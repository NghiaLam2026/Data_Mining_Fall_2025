# NYC Restaurant Inspection Grade Prediction - Presentation Content

## üé¨ 1. Title Slide

**Predicting NYC Restaurant Inspection Grades Using Pre-Inspection Features**

[Your Name]  
Data Mining - Fall 2025

---

## üß≠ 2. Problem Statement / Motivation

**Why This Matters:**
- NYC inspects **thousands of restaurants** each year, assigning **A/B/C grades** to protect public health
- **21,165 unique restaurants** with **83,603 inspections** in our dataset
- Can we identify **high-risk restaurants before inspectors visit**?

**Research Question:**
- Can we predict inspection grades using **only pre-inspection information**?
- What patterns exist in restaurant violations across **geography, cuisine, and time**?
- How well can models perform **without data leakage** from inspection results?

**Challenge:**
- Most predictive features (SCORE, violations) are **post-inspection** ‚Üí would create unrealistic predictions
- Need to use only information available **before the inspection occurs**

---

## üó∫ 3. Dataset Overview

**Dataset Characteristics:**
- **Original size:** 103,426 rows √ó 26 columns
- **After cleaning:** 83,603 rows (removed missing scores, non-A/B/C grades)
- **Time period:** 2012-2023
- **Geographic coverage:** All 5 NYC boroughs

**Key Columns:**
- **Identifiers:** CAMIS (restaurant ID), DBA (name), address
- **Location:** Latitude, Longitude, BORO, ZIPCODE
- **Restaurant info:** CUISINE DESCRIPTION, PHONE
- **Inspection data:** INSPECTION DATE, INSPECTION TYPE, SCORE, GRADE
- **Violations:** VIOLATION CODE, VIOLATION DESCRIPTION, CRITICAL FLAG
- **Geographic metadata:** Community Board, Council District, Census Tract

**Data Characteristics:**
- **Multiple inspections per restaurant** (average ~4 per restaurant)
- **Temporal patterns** - inspection policies change over time
- **Class imbalance:** A (82%), B (12%), C (6%)
- **Requires careful handling** to avoid data leakage

---

## üßπ 4. Data Cleaning Steps

**1. Duplicate Removal**
- Removed exact duplicate rows (0 duplicates found)

**2. Data Type Conversion**
- Converted date columns to datetime: INSPECTION DATE, GRADE DATE, RECORD DATE
- Converted ZIPCODE to string (preserve leading zeros)
- Set categorical types: BORO, CUISINE DESCRIPTION, INSPECTION TYPE, GRADE

**3. Missing Value Handling**
- Dropped 50 rows with missing SCORE (required for analysis)
- Dropped 19,773 rows with non-A/B/C grades (simplified classification)

**4. Feature Engineering**
- Extracted INSPECTION_YEAR and INSPECTION_MONTH from INSPECTION DATE
- Final dataset: **83,603 rows** ready for modeling

**5. Data Quality Checks**
- Verified geographic coordinates (Latitude/Longitude) are valid
- Ensured chronological order per restaurant
- Validated grade assignments match score ranges

---

## üß™ 5. Exploratory Data Analysis (EDA)

### Key Findings:

**1. Grade Distribution (Severe Imbalance)**
- **Grade A:** 68,421 (81.8%) - Dominant class
- **Grade B:** 9,972 (11.9%)
- **Grade C:** 5,210 (6.2%)

**2. Geographic Patterns**
- **Manhattan:** Highest number of inspections (31,165)
- **Brooklyn:** Second highest (22,107)
- **Staten Island:** Lowest (3,210)
- Geographic clustering visible in scatter plots

**3. Temporal Trends**
- **Average scores increased over time:**
  - 2012: 7.0
  - 2019: 12.7
  - 2023: 13.9
- Suggests changing inspection standards or restaurant improvements

**4. Cuisine Patterns**
- **Top cuisines:** American (16,028), Chinese (7,424), Coffee/Tea (6,131)
- Different cuisines show varying grade distributions
- Some cuisines have higher violation rates

**5. Borough-Level Differences**
- Grade distributions vary by borough
- Manhattan has highest proportion of A grades
- Bronx shows different patterns than other boroughs

**6. Score Distribution**
- Scores range from 0 (perfect) to higher values
- Strong negative correlation with grades (lower score = better grade)
- Clear separation between A, B, C grade score ranges

---

## üß± 6. Feature Engineering

### Final Feature Set (6 Pre-Inspection Features):

**1. Geographic Features:**
- **Latitude** - North-south location in NYC
- **Longitude** - East-west location in NYC
- **BORO** (categorical) - Borough (Bronx, Brooklyn, Manhattan, Queens, Staten Island)

**2. Restaurant Characteristics:**
- **CUISINE DESCRIPTION** (categorical) - Type of cuisine served

**3. Temporal Features:**
- **INSPECTION_YEAR** - Year of inspection (2012-2023)
- **INSPECTION_MONTH** - Month of inspection (1-12)

### Why These Features?

‚úÖ **Pre-inspection:** All known before inspection occurs  
‚úÖ **Non-leaky:** Don't contain inspection results  
‚úÖ **Interpretable:** Make business sense  
‚úÖ **Predictive:** Capture geographic, operational, and temporal patterns

### Features Excluded (Post-Inspection):

‚ùå **SCORE** - Directly determines GRADE (data leakage)  
‚ùå **HAS_VIOLATION** - Derived from SCORE  
‚ùå **CRITICAL_BINARY** - Inspection result  
‚ùå **VIOLATION CODE/DESCRIPTION** - Determined during inspection  
‚ùå **INSPECTION TYPE** - Can leak information about outcome

### Feature Selection Rationale:

- **Geographic features** capture neighborhood effects, socioeconomic patterns, inspector behavior
- **Cuisine type** reflects operational complexity and food safety requirements
- **Temporal features** capture policy changes, seasonality, and long-term trends

---

## ü§ñ 7. Modeling Approach

### Models Used:

**1. Logistic Regression (Baseline)**
- **Type:** Multinomial logistic regression
- **Why:** Linear baseline, interpretable coefficients
- **Configuration:** 
  - Multi-class classification
  - Class weight balancing
  - LBFGS solver

**2. Random Forest**
- **Type:** Ensemble of decision trees
- **Why:** Handles non-linear patterns, geographic partitions
- **Configuration:**
  - 300 estimators
  - Class weight balancing
  - Handles mixed feature types well

**3. XGBoost**
- **Type:** Gradient boosting
- **Why:** Powerful for tabular data, handles imbalance
- **Configuration:**
  - 300 estimators
  - Max depth: 4
  - Learning rate: 0.1
  - Sample weights for class imbalance

### Model Selection Rationale:

- **Logistic Regression:** Simple baseline, shows linear relationships
- **Random Forest:** Captures complex geographic and categorical interactions
- **XGBoost:** State-of-the-art gradient boosting, good for imbalanced data

### Evaluation Strategy:

- **Grouped train-test split (70/30)** by restaurant ID
- Prevents data leakage (same restaurant in both sets)
- **21,165 unique restaurants**
- **Metrics:** Accuracy, Precision, Recall, F1-Score (weighted)

---

## üìä 8. Results & Evaluation

### Model Performance Comparison (Test Set):

| Model | Train Accuracy | Test Accuracy | Precision | Recall | F1-Score |
|-------|---------------|---------------|-----------|--------|----------|
| **Logistic Regression** | ~0.48 | **0.482** | 0.48 | 0.48 | 0.48 |
| **XGBoost** | 0.673 | **0.576** | 0.75 | 0.58 | 0.64 |
| **Random Forest** | 0.999 | **0.801** | 0.71 | 0.80 | 0.74 |

### Key Observations:

**1. Random Forest Performs Best**
- **80.1% test accuracy** - highest among all models
- Captures non-linear geographic and categorical patterns
- Handles feature interactions well

**2. Class Imbalance Challenge**
- Models struggle with **B and C classes** (rare)
- Most predictions default to **Grade A** (majority class)
- This is **expected** given:
  - Only static pre-inspection features
  - No historical behavior data
  - Severe class imbalance (82% A)

**3. Overfitting in Random Forest**
- Train accuracy: 99.9% (near-perfect)
- Test accuracy: 80.1% (good but lower)
- Suggests model memorizes some patterns but generalizes reasonably

**4. Logistic Regression Baseline**
- Lowest performance (48.2%)
- Shows that **non-linear relationships** are important
- Linear model insufficient for this problem

### Confusion Matrix Insights:

- **Random Forest:** Best at predicting A, struggles with B/C
- **XGBoost:** Better precision for A, but lower recall
- **Logistic Regression:** Poor performance across all classes

### Interpretation:

‚úÖ **Results make sense:**
- Geographic and temporal patterns are predictive
- Without historical data, predicting rare classes (B/C) is extremely difficult
- Tree-based models outperform linear models (non-linear patterns exist)
- 80% accuracy is **good** given only pre-inspection features

---

## üîç 9. Key Insights

### Major Takeaways:

**1. Geography Matters**
- **Latitude and Longitude** are highly predictive
- Borough-level patterns exist
- Neighborhood effects are strong

**2. Temporal Patterns Are Important**
- **Inspection year** shows policy changes over time
- Scores have increased over time (2012: 7.0 ‚Üí 2023: 13.9)
- Suggests changing standards or improvements

**3. Cuisine Type Has Signal**
- Different cuisines have different violation patterns
- Operational complexity varies by cuisine type

**4. Class Imbalance Is a Major Challenge**
- **82% Grade A** makes B/C prediction extremely difficult
- Models default to predicting A
- Would need historical features or different approach for B/C

**5. Non-Linear Models Outperform Linear**
- Random Forest (80%) >> Logistic Regression (48%)
- Geographic and categorical interactions are complex
- Tree-based models capture these patterns better

**6. Data Leakage Prevention Is Critical**
- Excluding post-inspection features (SCORE, violations) is essential
- Pre-inspection features still achieve reasonable performance
- Shows importance of careful feature selection

**7. Feature Engineering Philosophy**
- **Pre-inspection features only** ‚Üí realistic prediction scenario
- Geographic proxies capture many underlying factors
- Temporal features capture policy and seasonal effects

---

## üöß 10. Limitations

### Acknowledged Constraints:

**1. Static Features Only**
- No historical behavior (previous scores, grades, violation history)
- Cannot capture restaurant improvement/decline trends
- Missing key predictive signal

**2. Severe Class Imbalance**
- **82% Grade A** makes B/C prediction extremely difficult
- Models default to majority class
- Would need specialized techniques (SMOTE, cost-sensitive learning)

**3. Limited Feature Set**
- Only 6 features (geographic, cuisine, temporal)
- Missing potentially useful features:
  - Restaurant age
  - Previous inspection history
  - Neighborhood demographics
  - Violation type patterns

**4. Inspection Date Selection Bias**
- Inspection dates reflect policy, not restaurant behavior
- Some restaurants inspected more frequently
- Temporal patterns may reflect policy changes, not restaurant quality

**5. Population-Level Predictions**
- Models predict **trends**, not individual restaurant outcomes
- Geographic patterns dominate
- Less useful for specific restaurant prediction

**6. No Text Analysis**
- Violation descriptions not analyzed (NLP potential)
- Could extract violation type patterns
- Rich text data unused

**7. Grouped Split Limitations**
- Prevents same restaurant in train/test
- But doesn't account for temporal ordering
- Could use time-based splits for more realistic evaluation

**8. Model Interpretability**
- Random Forest is less interpretable than linear models
- Feature importance available but not deep interpretation
- Trade-off between performance and explainability

---

## üöÄ 11. Future Work

### Potential Improvements:

**1. Historical Feature Engineering**
- **PREV_SCORE** - Previous inspection score
- **PREV_GRADE** - Previous inspection grade
- **DAYS_SINCE_LAST** - Time since last inspection
- **NUM_PAST_INSPECTIONS** - Inspection history count
- **ROLLING_AVG_SCORE** - Moving average of past scores
- **GRADE_TREND** - Improving/declining pattern

**2. Advanced Models**
- **CatBoost** - Handles categoricals natively
- **LightGBM** - Faster, often better than XGBoost
- **Neural Networks** - Deep learning for complex patterns
- **Ensemble Methods** - Combine multiple models

**3. Class Imbalance Solutions**
- **SMOTE** - Synthetic minority oversampling
- **Cost-sensitive learning** - Penalize B/C misclassification more
- **Focal Loss** - Focus on hard examples
- **Class weights** - Already used, but could tune

**4. Feature Engineering**
- **Neighborhood demographics** - Income, population density
- **Restaurant age** - Years in business
- **Violation type analysis** - NLP on violation descriptions
- **Spatial features** - Distance to nearest low-grade restaurant
- **Temporal features** - Day of week, seasonality

**5. Evaluation Improvements**
- **Time-based splits** - Train on past, test on future
- **Per-class metrics** - Focus on B/C recall
- **Business metrics** - Cost of false negatives (missed C grades)

**6. Advanced Analysis**
- **NLP on violations** - Extract violation type patterns
- **Interactive dashboard** - Map-based visualization
- **Risk ranking system** - Score restaurants by risk level
- **Inspector bias analysis** - Model inspector effects
- **Causal inference** - What causes violations?

**7. Deployment Considerations**
- **Real-time prediction API**
- **Integration with inspection scheduling**
- **Alert system for high-risk restaurants**
- **Dashboard for health department**

---

## üéâ 12. Conclusion

### Summary:

**What We Learned:**
- NYC restaurant inspection data is **rich and complex**
- **Clean, non-leaky modeling** is essential for realistic predictions
- **Geographic and temporal patterns** are highly predictive
- **Static pre-inspection features** can achieve ~80% accuracy
- **Class imbalance** is a major challenge for rare classes (B/C)
- **Tree-based models** outperform linear models for this problem

**Key Achievements:**
‚úÖ Built a **realistic prediction model** using only pre-inspection features  
‚úÖ Achieved **80% accuracy** with Random Forest  
‚úÖ Demonstrated **data leakage prevention** best practices  
‚úÖ Identified **geographic and temporal patterns** in violations  
‚úÖ Compared **three different modeling approaches**

**Main Takeaway:**
> "This project taught me the importance of **data leakage prevention**, **temporal feature engineering**, and **interpreting models not just by accuracy but by domain logic**. While 80% accuracy is good, the real value is understanding **why** models make predictions and **what features matter** for restaurant safety."

**Impact:**
- Could help health departments **prioritize inspections**
- Identifies **geographic risk patterns**
- Demonstrates **feasibility of pre-inspection prediction**
- Foundation for **future work with historical features**

---

## üìù Additional Slides (Optional)

### Feature Importance Analysis

**Random Forest Top Features:**
1. Geographic features (Latitude/Longitude) - Strongest predictors
2. Cuisine type categories - Operational patterns
3. Temporal features (Year/Month) - Policy and seasonal effects

**Logistic Regression Coefficients:**
- Show which features increase/decrease probability of each grade
- Interpretable but lower performance

**XGBoost Feature Importance:**
- Similar to Random Forest
- Geographic features dominate

### Data Leakage Prevention

**Why It Matters:**
- Using SCORE would give ~95% accuracy (trivial)
- Using post-inspection features creates unrealistic predictions
- Pre-inspection features ‚Üí realistic deployment scenario

**Our Approach:**
- Only features known before inspection
- Grouped train-test split by restaurant
- No violation information used

---

## üéØ Presentation Tips

1. **Keep slides visual** - Use plots from EDA, not code
2. **Tell a story** - Problem ‚Üí Data ‚Üí Solution ‚Üí Results ‚Üí Insights
3. **Emphasize data leakage prevention** - Shows sophistication
4. **Acknowledge limitations** - Shows maturity
5. **Highlight future work** - Shows ambition
6. **Focus on interpretation** - Not just numbers, but what they mean
7. **Use the confusion matrices** - Visual and informative
8. **Show feature importance plots** - Demonstrates understanding

---